{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fec5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.14.0 | packaged by Anaconda, Inc. | (main, Oct  8 2025, 17:15:28) [GCC 11.2.0]\n",
      "Python executable: /home/guru/miniconda3/envs/DINO/bin/python\n",
      "Kernel is working!\n"
     ]
    }
   ],
   "source": [
    "# Basic kernel test\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(\"Kernel is working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d3e8d",
   "metadata": {},
   "source": [
    "## Quick Test - Kernel Check\n",
    "\n",
    "Run this first to verify the kernel works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69124b1e",
   "metadata": {},
   "source": [
    "# Dinosaur Game Environment with Pygame\n",
    "## Part 1: Setup and Game Implementation\n",
    "\n",
    "This notebook implements the Chrome Dinosaur game environment using Pygame, compatible with OpenAI Gym interface for reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a60b0c",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc37ba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.0.20, Python 3.14.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Pygame version: 2.6.1\n",
      "NumPy version: 2.3.4\n",
      "Gymnasium version: 1.2.1\n",
      "Game module imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:491: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n",
      "/home/guru/miniconda3/envs/DINO/lib/python3.14/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "# Import the game module and other required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/mnt/c/Dino RL')\n",
    "\n",
    "# Prevent pygame from crashing in WSL/notebook environment\n",
    "# Set to use dummy video driver if no DISPLAY (will be overridden if render=True)\n",
    "if not os.environ.get('DISPLAY'):\n",
    "    os.environ['SDL_VIDEODRIVER'] = 'dummy'\n",
    "\n",
    "from src.dino_game import Dinosaur, Obstacle, DinoGame\n",
    "import pygame\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "# Display versions\n",
    "print(f\"Pygame version: {pygame.version.ver}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Gymnasium version: {gym.__version__}\")\n",
    "print(\"Game module imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db26840e",
   "metadata": {},
   "source": [
    "## 2. Game Classes (Imported from Module)\n",
    "\n",
    "The game implementation (Dinosaur, Obstacle, DinoGame) is now in `src/dino_game.py` and imported above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75355dd5",
   "metadata": {},
   "source": [
    "## 3. Create Gym Environment Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98024922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DinoEnv Gym wrapper created!\n"
     ]
    }
   ],
   "source": [
    "class DinoEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    OpenAI Gym compatible environment for Dino game\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human', 'none']}\n",
    "    \n",
    "    def __init__(self, render_mode='human'):\n",
    "        super(DinoEnv, self).__init__()\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # Actions: 0 = do nothing, 1 = jump, 2 = duck\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        \n",
    "        # Observation space: 8 features\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0, -1, 0, 0, 0, 0, 0, 0], dtype=np.float32),\n",
    "            high=np.array([1, 1, 1, 1, 1, 1, 1, 1], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        # DinoGame uses 'render' parameter (True/False), not 'render_mode'\n",
    "        should_render = (render_mode == 'human')\n",
    "        self.game = DinoGame(render=should_render)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment\"\"\"\n",
    "        return self.game.reset()\n",
    "        \n",
    "    def step(self, action):\n",
    "        \"\"\"Execute action in environment\"\"\"\n",
    "        return self.game.step(action)\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"Render the environment\"\"\"\n",
    "        self.game.render()\n",
    "        \n",
    "    def close(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.game.close()\n",
    "\n",
    "print(\"DinoEnv Gym wrapper created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563881c1",
   "metadata": {},
   "source": [
    "## 4. Test the Environment - Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdc8eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test the environment with a random agent\n",
    "print(\"Testing environment with random agent...\")\n",
    "print(\"This will run for a few episodes. Close the window or wait for game over.\")\n",
    "\n",
    "env = DinoEnv(render_mode='human')\n",
    "\n",
    "# Run a few episodes\n",
    "num_episodes = 3\n",
    "for episode in range(num_episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    \n",
    "    print(f\"\\n=== Episode {episode + 1} ===\")\n",
    "    \n",
    "    while not done and steps < 1000:  # Limit steps per episode\n",
    "        # Handle pygame events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                done = True\n",
    "                break\n",
    "                \n",
    "        # Take random action\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "        # Render\n",
    "        env.render()\n",
    "        \n",
    "        if done:\n",
    "            print(f\"Episode finished!\")\n",
    "            print(f\"Final Score: {info['score']}\")\n",
    "            print(f\"Total Reward: {total_reward:.2f}\")\n",
    "            print(f\"Steps: {steps}\")\n",
    "            break\n",
    "            \n",
    "env.close()\n",
    "print(\"\\nEnvironment test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bfd2f",
   "metadata": {},
   "source": [
    "## 5. Test Manual Control (Optional)\n",
    "\n",
    "You can manually control the dinosaur with keyboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28bf2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual control test - play the game yourself!\n",
    "print(\"Manual Control Test\")\n",
    "print(\"Controls: SPACE or UP arrow to jump, DOWN arrow to duck\")\n",
    "print(\"Close the window to stop\")\n",
    "\n",
    "env = DinoEnv(render_mode='human')\n",
    "obs = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "running = True\n",
    "while running and not done:\n",
    "    action = 0  # Default: do nothing\n",
    "    \n",
    "    # Handle events\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "            \n",
    "    # Check keyboard state\n",
    "    keys = pygame.key.get_pressed()\n",
    "    if keys[pygame.K_SPACE] or keys[pygame.K_UP]:\n",
    "        action = 1  # Jump\n",
    "    elif keys[pygame.K_DOWN]:\n",
    "        action = 2  # Duck\n",
    "        \n",
    "    # Step environment\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    # Render\n",
    "    env.render()\n",
    "    \n",
    "    if done:\n",
    "        print(f\"\\nGame Over!\")\n",
    "        print(f\"Final Score: {info['score']}\")\n",
    "        print(f\"Total Reward: {total_reward:.2f}\")\n",
    "        print(f\"Frames Survived: {info['frames']}\")\n",
    "\n",
    "env.close()\n",
    "print(\"Manual control test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9b127",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Environment Complete!**\n",
    "\n",
    "We've created:\n",
    "1. **Dinosaur class** - Character with jump and duck actions\n",
    "2. **Obstacle class** - Cacti and birds that move towards the dino\n",
    "3. **DinoGame class** - Main game logic with physics and collision detection\n",
    "4. **DinoEnv** - OpenAI Gym wrapper for RL training\n",
    "5. **State space** - 8 features describing game state\n",
    "6. **Action space** - 3 actions (nothing, jump, duck)\n",
    "7. **Reward system** - +0.1 per frame, +10 per obstacle passed, -100 for collision\n",
    "\n",
    "**Next Steps:**\n",
    "- Create the DQN model notebook\n",
    "- Train the agent using this environment\n",
    "- Optimize hyperparameters for better performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DINO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
